library(igraph)
install.packages("igraph")
install.packages("rgl")
install.packages("data.table")
install.packages("RPostgreSQL")
install.packages("reshape")
library(igraph)
library(rgl)
library(data.table)
library(RPostgreSQL)
library(reshape)
# setwd("~/Google Drive/Data at TWI/Pursuits/Robo advice")
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
#read data from db
q <- "select * from asset"
assets <- data.table(dbGetQuery(db, q))
q <- "select * from assetdata";
stockInfo <- data.table(dbGetQuery(db, q))
#disconnect from db
dbDisconnect(db)
dbUnloadDriver(drv)
#take reqd columns and pivot asset price data and change column names
stockPrice <- stockInfo[,list(timestamp,asset_id,price)]
stockPrice <- cast(stockPrice, timestamp ~ asset_id)
stockPrice$timestamp <- as.Date(stockPrice$timestamp)
colnames(stockPrice)[1] <- 'Date'
colnames(stockPrice)[2:ncol(stockPrice)] <- lapply(colnames(stockPrice)[2:ncol(stockPrice)], function(x) {return(paste("stock",as.character(x),sep = ""))})
takeDifferenceToggle <- TRUE
allData <- stockPrice #from integration.R file
##remove na columns
allData <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
allData <- allData[with(allData, order(Date)), ]
# createMST <- function(allData,takeDifferenceToggle) {
## remove stocks with NA values
rm(closePrice)
closePrice <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
stockNum <- ncol(closePrice)-1
rowNum <- nrow(closePrice)
## create log return
rm(closePriceLog,closePriceLogDiff)
closePriceLog <- closePrice[2:(stockNum+1)]
closePriceLog <- log10(closePriceLog)
closePriceLog$Date <- as.Date(closePrice$Date, "%m/%d/%y")
if(takeDifferenceToggle) {
closePriceLogDiff <- data.frame(closePriceLog[2:rowNum,]) - data.frame(closePriceLog[1:rowNum-1,])
closePriceLogDiff$Date <- closePriceLog[1:rowNum-1,]$Date
}else {
closePriceLogDiff <- closePriceLog
}
colnames(closePriceLogDiff) <- colnames(closePriceLog)
## create correlation matrix, and directed graph using correlation and causality
rm(corMatrix,edges,weights,negToPosLagRatioMatrix)
corMatrix <- cor(data.frame(closePriceLogDiff[1:stockNum]))
edges <- c()
weights <- c()
negToPosLagRatioMatrix <- matrix(0, nrow = stockNum, ncol = stockNum)
colnames(negToPosLagRatioMatrix) <- colnames(data.frame(closePriceLogDiff[1:stockNum]))
rownames(negToPosLagRatioMatrix) <- colnames(data.frame(closePriceLogDiff[1:stockNum]))
for (i in 1:stockNum) {
for (j in 0+i:stockNum) {
if (i!=j) {
l = 100
lagCorrel = ccf(closePriceLogDiff[i],closePriceLogDiff[j],l)
sumSquaresNegtv = 0
sumSquaresPostv = 0
for (k in 1:l) {
temp <- lagCorrel$acf
sumSquaresPostv <- sumSquaresPostv + (temp[k+l+1] * temp[k+l+1])
sumSquaresNegtv <- sumSquaresNegtv + (temp[k] * temp[k])
}
sumSquaresPostv <- sqrt(sumSquaresPostv)
sumSquaresNegtv <- sqrt(sumSquaresNegtv)
negToPosLagRatio <- (sumSquaresPostv - sumSquaresNegtv)*100/sumSquaresPostv
negToPosLagRatioMatrix[i,j] <- negToPosLagRatio
if (negToPosLagRatio < -4) {
edges <- c(edges,i,j)
weights <- c(weights,1-(corMatrix[i,j] * corMatrix[i,j]))
}
else if(negToPosLagRatio > 4){
edges <- c(edges,j,i)
weights <- c(weights,1-(corMatrix[i,j] * corMatrix[i,j]))
}
}
}
}
## create graph and mst
g<-graph(edges, n=max(edges), directed = TRUE)
g<-set.vertex.attribute(g, "name", value=colnames(closePriceLog)[1:stockNum])
gmst <- mst(g,weights = weights)
# plot(gmst,vertex.size = 8,edge.arrow.size=0.5)
## prepare to export results to db
mstEdges <- data.frame(get.edgelist(gmst))
colnames(mstEdges) <- c("assetIdOne_id","assetIdTwo")
mstEdges$assetIdOne_id <- as.character(mstEdges$assetIdOne_id)
mstEdges$assetIdTwo <- as.character(mstEdges$assetIdTwo)
mstEdges$intercept <- 0
mstEdges$slope <- 0
coefficients <- apply(mstEdges,1, function(x){
model1 <- lm(as.formula(paste(x[[2]], "~",x[[1]])),data=closePriceLogDiff)
return(model1$coefficients)
})
for (i in 1:nrow(mstEdges)) {
mstEdges[i,1] <- substr(mstEdges[i,1],6,nchar(mstEdges[i,1]))
mstEdges[i,2] <- substr(mstEdges[i,2],6,nchar(mstEdges[i,2]))
mstEdges[i,3] <- coefficients[1,i]
mstEdges[i,4] <- coefficients[2,i]
}
# write.csv(mstEdges,file = "mstEdges.csv")
# write.csv(closePriceLogDiff,file = "closePriceLogDiff.csv")
# write.csv(corMatrix,file = "correlationMatrix.csv")
## save results to db
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
dbWriteTable(db,"minimum_spanning_tree_model",mstEdges,overwrite=TRUE,row.names=FALSE)
dbDisconnect(db)
dbUnloadDriver(drv)
# }
rm(list = ls())
library(igraph)
library(rgl)
library(data.table)
library(RPostgreSQL)
library(reshape)
# setwd("~/Google Drive/Data at TWI/Pursuits/Robo advice")
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
#read data from db
q <- "select * from asset"
assets <- data.table(dbGetQuery(db, q))
q <- "select * from assetdata";
stockInfo <- data.table(dbGetQuery(db, q))
#disconnect from db
dbDisconnect(db)
dbUnloadDriver(drv)
#take reqd columns and pivot asset price data and change column names
stockPrice <- stockInfo[,list(timestamp,asset_id,price)]
stockPrice <- cast(stockPrice, timestamp ~ asset_id)
stockPrice <- stockPrice[100:nrow(stockPrice),]
stockPrice$timestamp <- as.Date(stockPrice$timestamp)
colnames(stockPrice)[1] <- 'Date'
colnames(stockPrice)[2:ncol(stockPrice)] <- lapply(colnames(stockPrice)[2:ncol(stockPrice)], function(x) {return(paste("stock",as.character(x),sep = ""))})
takeDifferenceToggle <- TRUE
allData <- stockPrice #from integration.R file
##remove na columns
allData <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
allData <- allData[with(allData, order(Date)), ]
# createMST <- function(allData,takeDifferenceToggle) {
## remove stocks with NA values
rm(closePrice)
closePrice <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
stockNum <- ncol(closePrice)-1
rowNum <- nrow(closePrice)
## create log return
rm(closePriceLog,closePriceLogDiff)
closePriceLog <- closePrice[2:(stockNum+1)]
closePriceLog <- log10(closePriceLog)
closePriceLog$Date <- as.Date(closePrice$Date, "%m/%d/%y")
if(takeDifferenceToggle) {
closePriceLogDiff <- data.frame(closePriceLog[2:rowNum,]) - data.frame(closePriceLog[1:rowNum-1,])
closePriceLogDiff$Date <- closePriceLog[1:rowNum-1,]$Date
}else {
closePriceLogDiff <- closePriceLog
}
colnames(closePriceLogDiff) <- colnames(closePriceLog)
## create correlation matrix, and directed graph using correlation and causality
rm(corMatrix,edges,weights,negToPosLagRatioMatrix)
corMatrix <- cor(data.frame(closePriceLogDiff[1:stockNum]))
edges <- c()
weights <- c()
negToPosLagRatioMatrix <- matrix(0, nrow = stockNum, ncol = stockNum)
colnames(negToPosLagRatioMatrix) <- colnames(data.frame(closePriceLogDiff[1:stockNum]))
rownames(negToPosLagRatioMatrix) <- colnames(data.frame(closePriceLogDiff[1:stockNum]))
for (i in 1:stockNum) {
for (j in 0+i:stockNum) {
if (i!=j) {
l = 100
lagCorrel = ccf(closePriceLogDiff[i],closePriceLogDiff[j],l)
sumSquaresNegtv = 0
sumSquaresPostv = 0
for (k in 1:l) {
temp <- lagCorrel$acf
sumSquaresPostv <- sumSquaresPostv + (temp[k+l+1] * temp[k+l+1])
sumSquaresNegtv <- sumSquaresNegtv + (temp[k] * temp[k])
}
sumSquaresPostv <- sqrt(sumSquaresPostv)
sumSquaresNegtv <- sqrt(sumSquaresNegtv)
negToPosLagRatio <- (sumSquaresPostv - sumSquaresNegtv)*100/sumSquaresPostv
negToPosLagRatioMatrix[i,j] <- negToPosLagRatio
if (negToPosLagRatio < -4) {
edges <- c(edges,i,j)
weights <- c(weights,1-(corMatrix[i,j] * corMatrix[i,j]))
}
else if(negToPosLagRatio > 4){
edges <- c(edges,j,i)
weights <- c(weights,1-(corMatrix[i,j] * corMatrix[i,j]))
}
}
}
}
## create graph and mst
g<-graph(edges, n=max(edges), directed = TRUE)
g<-set.vertex.attribute(g, "name", value=colnames(closePriceLog)[1:stockNum])
gmst <- mst(g,weights = weights)
# plot(gmst,vertex.size = 8,edge.arrow.size=0.5)
## prepare to export results to db
mstEdges <- data.frame(get.edgelist(gmst))
colnames(mstEdges) <- c("assetIdOne_id","assetIdTwo")
mstEdges$assetIdOne_id <- as.character(mstEdges$assetIdOne_id)
mstEdges$assetIdTwo <- as.character(mstEdges$assetIdTwo)
mstEdges$intercept <- 0
mstEdges$slope <- 0
coefficients <- apply(mstEdges,1, function(x){
model1 <- lm(as.formula(paste(x[[2]], "~",x[[1]])),data=closePriceLogDiff)
return(model1$coefficients)
})
for (i in 1:nrow(mstEdges)) {
mstEdges[i,1] <- substr(mstEdges[i,1],6,nchar(mstEdges[i,1]))
mstEdges[i,2] <- substr(mstEdges[i,2],6,nchar(mstEdges[i,2]))
mstEdges[i,3] <- coefficients[1,i]
mstEdges[i,4] <- coefficients[2,i]
}
# write.csv(mstEdges,file = "mstEdges.csv")
# write.csv(closePriceLogDiff,file = "closePriceLogDiff.csv")
# write.csv(corMatrix,file = "correlationMatrix.csv")
## save results to db
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
dbWriteTable(db,"minimum_spanning_tree_model",mstEdges,overwrite=TRUE,row.names=FALSE)
dbDisconnect(db)
dbUnloadDriver(drv)
# }
plot(gmst,vertex.size = 8,edge.arrow.size=0.5)
library(RPostgreSQL)
library(data.table)
library(reshape)
#list of edges in mst
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
q <- "select * from news_group"
news <- data.table(dbGetQuery(db, q))
q <- "select * from minimum_spanning_tree_model"
mstEdges <- data.table(dbGetQuery(db, q))
q <- "select * from assetdata";
stockInfo <- data.table(dbGetQuery(db, q))
dbDisconnect(db)
dbUnloadDriver(drv)
stockPrice <- stockInfo[,list(timestamp,asset_id,price)]
stockPrice <- cast(stockPrice, timestamp ~ asset_id)
stockPrice <- stockPrice[100:nrow(stockPrice),]
stockPrice$timestamp <- as.Date(stockPrice$timestamp)
colnames(stockPrice)[1] <- 'Date'
colnames(stockPrice)[2:ncol(stockPrice)] <- lapply(colnames(stockPrice)[2:ncol(stockPrice)], function(x) {return(paste("stock",as.character(x),sep = ""))})
news$assetId_id <- paste("stock",news$asset_id,sep = "")
mstEdges$assetIdOne_id <- paste("stock",mstEdges$assetIdOne_id,sep = "")
mstEdges$assetIdTwo <- paste("stock",mstEdges$assetIdTwo,sep = "")
#mstEdges <- read.csv("mstEdges.csv")
#mstEdges$X <- NULL
#closePriceLogDiff <- read.csv("closePriceLogDiff.csv")
#closePriceLogDiff$X<- NULL
numStocks <- ncol(stockPrice)-1
#latestLogReturns <- closePriceLogDiff[1,1:40]
#latestLogReturns <- c(latestLogReturns[1,])
newsEffect <- function(stockName,effect=0.005) {
#create list of 40 zeroes to depict effect due to news for each of 40 stocks
currentNewsEffect <- as.list(stockPrice[1,2:(numStocks+1)])
currentNewsEffect[1:numStocks] <- 0
sourceList <- c(stockName)
currentNewsEffect[stockName] <- effect
while (length(sourceList)!=0) {
sourceNode <- sourceList[1]
print(sourceNode)
destList <- as.list(as.character(mstEdges[mstEdges$assetIdOne_id==sourceNode,]$assetIdTwo))
while(length(destList)!=0) {
dest <- destList[[1]]
print(dest)
sourceList <- c(sourceList, dest)
#model1 <- lm(as.formula(paste(dest, "~",sourceNode)),data=closePriceLogDiff)
#new <- data.frame(currentNewsEffect[sourceNode])
#colnames(new) <- c(sourceNode)
#result <- predict(model1,newdata = new)
#currentNewsEffect[dest] <- result
print(paste("source",sourceNode,sep = " "))
print(paste("dest",dest,sep = " "))
currentNewsEffect[dest] <- (currentNewsEffect[[sourceNode]] *
mstEdges[assetIdOne_id==sourceNode & assetIdTwo==dest,]$slope) +
mstEdges[assetIdOne_id==sourceNode & assetIdTwo==dest,]$intercept
destList <- destList[-1]
}
sourceList <- sourceList[-1]
}
return(currentNewsEffect)
}
# loop over all assets to predict
netEffect <- as.list(stockPrice[1,2:(numStocks+1)])
netEffect[1:numStocks] <- 0
netEffect <- data.frame(netEffect)
for (stock in news$assetId_id) {
temp <- newsEffect(stock,news[assetId_id==assetId_id,]$effect)
for (colname in colnames(netEffect)) {
netEffect[1,colname] <- netEffect[1,colname] + temp[[colname]]
}
}
colnames(netEffect) <- substr(colnames(netEffect),6,nchar(colnames(netEffect)))
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
for (stock_id in colnames(netEffect)) {
q = paste("update assetdata set neteffect =",netEffect[1,stock_id]," where asset_id = ",stock_id," AND timestamp = \'",max(stockInfo$timestamp-(19800)),"\'",sep = "")
print(dbGetQuery(db, q))
}
dbDisconnect(db)
dbUnloadDriver(drv)
rm(list = ls())
library(RPostgreSQL)
library(data.table)
library(reshape)
library(jsonlite)
## Loading data and taking relevant subset (of stocks having all data points without NAs)
# allData <- fread("nyseClosingPrice.csv")
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
#read data from db
q <- "select * from asset"
assets <- data.table(dbGetQuery(db, q))
q <- "select * from assetdata";
stockInfo <- data.table(dbGetQuery(db, q))
#disconnect from db
dbDisconnect(db)
dbUnloadDriver(drv)
#take reqd columns and pivot asset price data and change column names
allData <- unique(stockInfo[,list(timestamp,asset_id,price)])
allData <- cast(allData, timestamp ~ asset_id)
allData <- allData[100:nrow(allData),]
allData$timestamp <- as.Date(allData$timestamp)
colnames(allData)[1] <- 'Date'
colnames(allData)[2:ncol(allData)] <- lapply(colnames(allData)[2:ncol(allData)], function(x) {return(paste("stock",as.character(x),sep = ""))})
allData <- data.table(allData)
# allData$Date <- as.Date(allData$Date, "%m/%d/%y")
allData <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
allData <- allData[with(allData, order(Date)), ]
## Finding normalized log return of all data points
stockPrices <- allData[, 2:ncol(allData), with = FALSE]
logStockPrices <- log10(stockPrices)
logReturn <- data.table(diff(as.matrix(logStockPrices)))
logReturn <- logReturn[, Date:= allData[2:nrow(allData), Date]]
logReturn <- logReturn[, c(ncol(logReturn),1:(ncol(logReturn)-1)), with = FALSE]
# save(logReturn,file="logReturn.rda")
## function to create arima model
getArimaModel <- function(data,order){
#print(head(data))
fit <- arima(data,order = c(order,0L,0L),method = "ML")
}
## create models for each stock
arimaModelDF <- apply(logReturn[,-1,with=FALSE],MARGIN = 2,FUN =  function(x){return(getArimaModel(x,5))})
arimaModelDF$Date <- NULL
# save(arimaModelDF,file = "arimaModels.rda")
arimaModelToDB <- data.frame(stock_id=names(arimaModelDF),coeff1=0,coeff2=0,coeff3=0,coeff4=0,coeff5=0,intercept=0)
for (stock in names(arimaModelDF)) {
arimaModelToDB[arimaModelToDB$stock_id==stock,2:7] <- arimaModelDF[[stock]]$coef
}
arimaModelToDB$stock_id <- apply(arimaModelToDB, MARGIN =1, FUN = function(x) {
substr(x["stock_id"],6,nchar(x["stock_id"]))
})
# ## save arima model as data frame
# drv <- dbDriver("PostgreSQL")
# db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
#                 user="robouser", password="password")
#
# dbWriteTable(db,"arima_model",arimaModelToDB,overwrite=TRUE,row.names=FALSE)
#
# dbDisconnect(db)
# dbUnloadDriver(drv)
## save arima model as json
arimaJSONdf <- data.frame(apply(arimaModelToDB, MARGIN = 1, FUN = function(x) {
toJSON(x[2:length(x)])
}))
arimaJSONdf$asset_id <- arimaModelToDB$stock_id
colnames(arimaJSONdf)[1] <- c("coefficients")
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
# arimaJSON <- toJSON(arimaModelToDB)
dbWriteTable(db,"time_series_model",arimaJSONdf,overwrite=TRUE,row.names=FALSE)
dbDisconnect(db)
dbUnloadDriver(drv)
# ## get prediction using model
# getTimeSeriesPrediction <- function(stockName,newdata) {
#   refit <- Arima(newdata, model = arimaModelDF[[stockName]])
#   prediction <- predict(refit,n.ahead=1)
#   return(prediction$pred[1])
# }
# arimaModelDF <- lapply(logReturn[1:701], function(x){return(getArimaModel(x,5))})
# arimaPredictions <- logReturn[1]
# arimaPredictions$Date <- NULL
# for (stockName in colnames(logReturn)[2:ncol(logReturn)]) {
#   refit <- Arima(logReturn[[stockName]][702:757],model = arimaModelDF[[stockName]])
#   prediction <- predict(refit,n.ahead=1)
#   print(prediction$pred[1])
# }
################################
## find right order
# MEList <- c()
# for (i in 10:12) {
#   print(i)
#   arimaModelDF <- lapply(logReturn[1:701], function(x){return(getArimaModel(x,i))})
#   arimaModelDF$Date <- NULL
#   totalME <- 0
#   for (stockName in colnames(logReturn)[2:ncol(logReturn)]) {
#     refit <- Arima(logReturn[[stockName]][702:757],model = arimaModelDF[[stockName]])
#     totalME <- totalME + accuracy(refit)[1]
#   }
#   MEList[i] <- totalME
# }
rm(list = ls())
library(RPostgreSQL)
library(data.table)
library(reshape)
library(jsonlite)
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
#read data from db
q <- "select * from assetdata";
stockInfo <- data.table(dbGetQuery(db, q))
q <- "select * from time_series_model";
arimaJSONdf <- data.table(dbGetQuery(db, q))
q <- "select * from news_group"
newsEffect <- data.table(dbGetQuery(db, q))
rm(q)
#disconnect from db
dbDisconnect(db)
dbUnloadDriver(drv)
#take reqd columns and pivot asset price data and change column names
allData <- unique(stockInfo[,list(timestamp,asset_id,price)])
allData <- cast(allData, timestamp ~ asset_id)
allData <- allData[100:nrow(allData),]
allData$timestamp <- as.Date(allData$timestamp)
colnames(allData)[1] <- 'Date'
colnames(allData)[2:ncol(allData)] <- lapply(colnames(allData)[2:ncol(allData)], function(x) {return(paste("stock",as.character(x),sep = ""))})
allData <- data.table(allData)
newsEffect$asset_id <- paste("stock",newsEffect$asset_id,sep = "")
# allData$Date <- as.Date(allData$Date, "%m/%d/%y")
allData <- set(allData, j = which(colSums(is.na(allData)) > 0), value = NULL)
allData <- allData[with(allData, order(Date)), ]
## Finding normalized log return of all data points
stockPrices <- allData[, 2:ncol(allData), with = FALSE]
logStockPrices <- log10(stockPrices)
logReturn <- data.table(diff(as.matrix(logStockPrices)))
logReturn <- logReturn[, Date:= allData[2:nrow(allData), Date]]
logReturn <- logReturn[, c(ncol(logReturn),1:(ncol(logReturn)-1)), with = FALSE]
## prediction by manual calculation
logReturnTrunk <- data.frame(tail(logReturn,5))
logReturnTrunk$Date <- as.character(logReturnTrunk$Date)
logReturnTrunk <- logReturnTrunk[with(logReturnTrunk, order(Date,decreasing = T)), ]
logReturnTrunk <- logReturnTrunk[,2:ncol(logReturn)]
logReturnTrunk <- rbind(logReturnTrunk,rep(1,ncol(logReturnTrunk)))
coefficients <- data.frame(apply(arimaJSONdf,MARGIN = 1,FUN = function(x){as.numeric(fromJSON(x[1]))}))
colnames(coefficients) <- paste("stock",arimaJSONdf$asset_id,sep = "")
## calculate timeseries prediction
predictionDF <- logReturnTrunk[1,] * 0
for (stock_id in colnames(predictionDF)) {
predictionDF[1,stock_id] <- (sum(logReturnTrunk[stock_id] * coefficients[stock_id])) +  ifelse(length(newsEffect[asset_id==stock_id,effect])==0,0,newsEffect[asset_id==stock_id,effect])
}
## add news effect
for (stock_id in colnames(predictionDF)) {
stock_id_temp <- substr(stock_id,6,nchar(stock_id))
predictionDF[1,stock_id] <- predictionDF[1,stock_id] + 0.01*(stockInfo[asset_id=="10" & timestamp==max(timestamp),]$neteffect)
}
## calculate price from log return
todayPrice <- allData[nrow(allData),]
tomorrowPrice <- todayPrice
tomorrowPrice$Date <- tomorrowPrice$Date + 1
for (asset_id in colnames(predictionDF)) {
tomorrowPrice[1,asset_id] <- 10^(predictionDF[1,asset_id] + log10(todayPrice[1,asset_id,with=F]))
}
colnames(tomorrowPrice) <- substr(colnames(tomorrowPrice),6,nchar(colnames(tomorrowPrice)))
## write prediction to db
drv <- dbDriver("PostgreSQL")
db <- dbConnect(drv, dbname="roboadvisordb", host= "localhost", port=5432,
user="robouser", password="password")
# for (stock_id in colnames(predictionDF)) {
#   temp <- as.character(max(stockInfo$timestamp+(3600*24)))
#   q = paste("update assetdata set prediction=",tomorrowPrice[1,stock_id,with=F]," where asset_id=",stock_id," AND timestamp=\"",max(stockInfo$timestamp+(3600*24)),"\"",sep = "")
#   print(dbGetQuery(db, q))
# }
for (stock_id in colnames(tomorrowPrice[,2:ncol(tomorrowPrice),with=F])) {
# print(stock_id)
temp <- as.character(max(stockInfo$timestamp-(19800)))
q = paste("update assetdata set prediction =",tomorrowPrice[1,stock_id,with=F]," where asset_id = ",stock_id," AND timestamp = \'",max(stockInfo$timestamp-(19800)),"\'",sep = "")
print(dbGetQuery(db, q))
# print(q)
}
#disconnect from db
dbDisconnect(db)
dbUnloadDriver(drv)
